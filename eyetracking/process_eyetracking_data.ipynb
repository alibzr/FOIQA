{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a2500b-026d-4796-b23c-971e2779775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import quaternion\n",
    "import pandas as pd\n",
    "from parse import parse\n",
    "from Salient360Toolbox import helper\n",
    "from Salient360Toolbox.generation import scanpath as scanp_generate\n",
    "from Salient360Toolbox.generation import saliency as sal_generate\n",
    "from natsort import natsorted\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7712fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(directory, ext):\n",
    "    # Use glob to get all files in the directory based on extensions\n",
    "    files = glob.glob(os.path.join(directory, ext))\n",
    "    \n",
    "    # Natural sort\n",
    "    files = natsorted(files)\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d021815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename):\n",
    "    # Extract the base filename without the directory path\n",
    "    base_filename = os.path.basename(filename)\n",
    "    \n",
    "    # Remove the file extension\n",
    "    base_filename = os.path.splitext(base_filename)[0]\n",
    "    \n",
    "    # Split the base filename by hyphens\n",
    "    parts = base_filename.split('-')\n",
    "    \n",
    "    # Ensure we have exactly 11 parts to match the format\n",
    "    if len(parts) != 11:\n",
    "        print(f\"Filename format is incorrect: {filename}\")\n",
    "        return None\n",
    "    \n",
    "    # Assign parts to respective variables based on the format\n",
    "    user_name = parts[0]\n",
    "    session_number = parts[1]\n",
    "    environment_number = parts[2]\n",
    "    world_rotation = parts[3]\n",
    "    context_factor = parts[4]\n",
    "    year = parts[5]\n",
    "    month = parts[6]\n",
    "    day = parts[7]\n",
    "    hour = parts[8]\n",
    "    minute = parts[9]\n",
    "    second = parts[10]\n",
    "    \n",
    "    # Create a dictionary to hold the parsed values\n",
    "    parsed_values = {\n",
    "        'userName': user_name,\n",
    "        'session_number': session_number,\n",
    "        'environment_number': environment_number,\n",
    "        'world_rotation': world_rotation,\n",
    "        'context_factor': context_factor,\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'day': day,\n",
    "        'hour': hour,\n",
    "        'minute': minute,\n",
    "        'second': second\n",
    "    }\n",
    "    \n",
    "    return parsed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2476b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_head_rotations(df, world_rotation):\n",
    "    \"\"\"Process head rotation data from DataFrame.\"\"\"\n",
    "    head_rotations = df[\"HMDRotation\"]\n",
    "    parsed_headrotations = [parse(\"({x}, {y}, {z}, {w})\", hr).named for hr in head_rotations]\n",
    "    df_headrotations = pd.DataFrame(pd.DataFrame(parsed_headrotations).astype(float), \n",
    "                                  columns=[\"x\", \"y\", \"z\", \"w\"])\n",
    "    \n",
    "    # Reorder columns and apply rotation correction\n",
    "    cols = list(df_headrotations.columns)\n",
    "    cols = [cols[-1]] + cols[:-1]\n",
    "    df_headrotations = df_headrotations[cols]\n",
    "    \n",
    "    qs_hr = quaternion.as_quat_array(df_headrotations)\n",
    "    rotation_correction = quaternion.from_euler_angles([\n",
    "        np.deg2rad(0), np.deg2rad(world_rotation), np.deg2rad(0)\n",
    "    ])\n",
    "    df_headrotations_corrected = pd.DataFrame(\n",
    "        quaternion.as_float_array(qs_hr * rotation_correction)\n",
    "    )\n",
    "    \n",
    "    # Add corrected head rotation columns to main DataFrame\n",
    "    df[\"xhead\"] = df_headrotations_corrected[1]\n",
    "    df[\"yhead\"] = df_headrotations_corrected[2]\n",
    "    df[\"zhead\"] = df_headrotations_corrected[3]\n",
    "    df[\"whead\"] = df_headrotations_corrected[0]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be574014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eye_directions(df):\n",
    "    \"\"\"Process eye direction data for both eyes and combined gaze.\"\"\"\n",
    "    # Process right eye\n",
    "    reye_directions = df[\"RightEyeForward\"]\n",
    "    parsed_reyedirections = [parse(\"({x}, {y}, {z})\", red).named for red in reye_directions]\n",
    "    df_reyedirections = pd.DataFrame(pd.DataFrame(parsed_reyedirections).astype(float),\n",
    "                                   columns=[\"x\", \"y\", \"z\"])\n",
    "    \n",
    "    # Process left eye\n",
    "    leye_directions = df[\"LeftEyeForward\"]\n",
    "    parsed_leyedirections = [parse(\"({x}, {y}, {z})\", led).named for led in leye_directions]\n",
    "    df_leyedirections = pd.DataFrame(pd.DataFrame(parsed_leyedirections).astype(float),\n",
    "                                   columns=[\"x\", \"y\", \"z\"])\n",
    "    \n",
    "    # Process combined gaze\n",
    "    beye_directions = df[\"CombinedGazeForward\"]\n",
    "    parsed_beyedirections = [parse(\"({x}, {y}, {z})\", bed).named for bed in beye_directions]\n",
    "    df_beyedirections = pd.DataFrame(pd.DataFrame(parsed_beyedirections).astype(float),\n",
    "                                   columns=[\"x\", \"y\", \"z\"])\n",
    "    \n",
    "    # Add eye direction columns to main DataFrame\n",
    "    for prefix, df_directions in [\n",
    "        (\"rightgaze\", df_reyedirections),\n",
    "        (\"leftgaze\", df_leyedirections),\n",
    "        (\"meangazedir\", df_beyedirections)\n",
    "    ]:\n",
    "        for axis in [\"x\", \"y\", \"z\"]:\n",
    "            df[f\"{prefix}{axis}\"] = df_directions[axis]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156fb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_visualization_maps(fix_list, dimension, savename, savepath, path_stim):\n",
    "    \"\"\"Generate and save various visualization maps.\"\"\"\n",
    "    # Generate saliency map\n",
    "    sal_map = helper.getSaliencyMap(\n",
    "        fix_list[:, [2,3,4,0,1]],\n",
    "        dimension,\n",
    "        name=savename,\n",
    "        path_save=savepath,\n",
    "        gauss_sigma=GAUSS_SIGMA,\n",
    "        force_return_data=True,\n",
    "        force_generate=False,\n",
    "        caching=False\n",
    "    )\n",
    "    \n",
    "    # Generate fixation map\n",
    "    fix_map = helper.getFixationMap(fix_list[:, :2], dimension)\n",
    "    sal_image = sal_generate.toImage(sal_map, cmap=SALIENCY_CMAP)\n",
    "    \n",
    "    # Save various visualization maps\n",
    "    fix_map_img = sal_generate.toImage(fix_map, cmap=FIXATION_CMAP, reverse=True)\n",
    "    sal_generate.saveImage(fix_map_img, savepath + \"_fixmap\")\n",
    "    sal_generate.saveImage(sal_image / sal_map.max() * 255, savepath + \"_salmap\")\n",
    "    sal_generate.saveImage(sal_image[:,:, [2,1,0]], savepath + \"_csalmap\")\n",
    "    sal_generate.saveImage(sal_map, savepath + \"_bsalmap\", blend=path_stim)\n",
    "    \n",
    "    # Generate and save scanpath visualization\n",
    "    scanp_generate.toImage(\n",
    "        fix_list[:, :2], \n",
    "        dimension, \n",
    "        savepath + \"_bscanpath\", \n",
    "        blend=path_stim\n",
    "    )\n",
    "    \n",
    "    # Save fixation data\n",
    "    scanp_generate.toFile(\n",
    "        fix_list, \n",
    "        savepath + \"_fixation.csv\",\n",
    "        saveArr=np.arange(fix_list.shape[1]), \n",
    "        mode=\"w\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de72c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eye_tracking_data(csv_file_paths, parsed_values_list, texture_paths, \n",
    "                            eye, tracking, resample, filterSettings, parsingSettings, dimension):\n",
    "    \"\"\"Process eye tracking data and generate visualization maps.\"\"\"\n",
    "    \n",
    "    for k in tqdm_notebook(range(1, len(csv_file_paths))):\n",
    "        # Get file paths and indices\n",
    "        path_raw_file = csv_file_paths[k]\n",
    "        environment_index = int(parsed_values_list[k].get(\"environment_number\"))\n",
    "        path_stim = texture_paths[environment_index-1]\n",
    "        \n",
    "        # Create output directory structure\n",
    "        parsed_values = list(parsed_values_list[k].values())\n",
    "        write_path = '\\\\'.join([PARENT_WRITE_PATH, \"-\".join(parsed_values)])\n",
    "        gazeLog_write_path = '\\\\'.join([write_path, 'gazelog.csv'])\n",
    "        \n",
    "        if not os.path.exists(write_path):\n",
    "            os.makedirs(write_path)\n",
    "        \n",
    "        # Load and clean data\n",
    "        df = pd.read_csv(path_raw_file, sep=\";\")\n",
    "        df.replace(\"INVALID\", np.nan, inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Process timestamps\n",
    "        initial_time = df.iloc[0,1]\n",
    "        df[\"ts\"] = df[\"CaptureTime\"].apply(lambda x: (x - initial_time) * 1e-6)\n",
    "        \n",
    "        # Process head rotations\n",
    "        world_rotation = int(parsed_values_list[k].get(\"world_rotation\"))\n",
    "        df = process_head_rotations(df, world_rotation)\n",
    "        \n",
    "        # Process eye directions\n",
    "        df = process_eye_directions(df)\n",
    "        \n",
    "        # Save processed gaze data\n",
    "        df.to_csv(gazeLog_write_path, columns=COLUMNS_TO_SAVE)\n",
    "        \n",
    "        # Generate gaze data and fixation list\n",
    "        gaze_data, fix_list = helper.loadRawData(\n",
    "            gazeLog_write_path,\n",
    "            eye=eye,\n",
    "            tracking=tracking,\n",
    "            resample=resample,\n",
    "            filter=filterSettings,\n",
    "            parser=parsingSettings\n",
    "        )\n",
    "        \n",
    "        # Generate and save visualization maps\n",
    "        savename = \"-\".join(parsed_values)\n",
    "        savepath = write_path + '\\\\'\n",
    "        generate_visualization_maps(\n",
    "            fix_list, dimension, savename, savepath, path_stim\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a533a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_paths = get_file_paths('raw_gaze', '*.csv')\n",
    "texture_paths = get_file_paths('textures', '*.jpg')\n",
    "\n",
    "# List to hold all parsed values\n",
    "parsed_values_list = []\n",
    "\n",
    "# Parse each CSV file's parameters\n",
    "for path in csv_file_paths:\n",
    "    parsed_values = parse_filename(path)\n",
    "    if parsed_values:\n",
    "        parsed_values_list.append(parsed_values)\n",
    "        \n",
    "# Tracking can be HE (Head+Eye) or H (Head alone)\n",
    "tracking = \"HE\"\n",
    "\n",
    "# Targeted eye\n",
    "eye = \"B\"\n",
    "\n",
    "# Resampling rate\n",
    "resample = 120\n",
    "\n",
    "# Filter settings\n",
    "filterSettings = {\"name\": \"savgol\", \"params\": {\"win\": 9, \"poly\": 2}}\n",
    "\n",
    "# Gaze parsing settings\n",
    "parsingSettings = {\"name\": \"I-VT\", \"params\": {\"threshold\": 120}}\n",
    "\n",
    "# Dimensions of output images (Height, Width)\n",
    "dimension = [8192, 16384]\n",
    "\n",
    "# Constants and settings\n",
    "PARENT_WRITE_PATH = 'processed_gaze'\n",
    "COLUMNS_TO_SAVE = [\n",
    "    \"ts\", \"xhead\", \"yhead\", \"zhead\", \"whead\",\n",
    "    \"rightgazex\", \"rightgazey\", \"rightgazez\",\n",
    "    \"leftgazex\", \"leftgazey\", \"leftgazez\",\n",
    "    \"meangazedirx\", \"meangazediry\", \"meangazedirz\"\n",
    "]\n",
    "\n",
    "# Saliency map settings\n",
    "GAUSS_SIGMA = 2\n",
    "SALIENCY_CMAP = \"coolwarm\"\n",
    "FIXATION_CMAP = \"binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b687e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_eye_tracking_data(\n",
    "    csv_file_paths=csv_file_paths,\n",
    "    parsed_values_list=parsed_values_list,\n",
    "    texture_paths=texture_paths,\n",
    "    eye=eye,\n",
    "    tracking=tracking,\n",
    "    resample=resample,\n",
    "    filterSettings=filterSettings,\n",
    "    parsingSettings=parsingSettings,\n",
    "    dimension=dimension\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salient",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
